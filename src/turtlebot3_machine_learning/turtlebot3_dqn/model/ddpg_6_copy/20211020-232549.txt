episode, reward, duration, n_steps, epsilon, success_count, memory length, avg_critic_loss, avg_actor_loss
2601, 4010.6502726078033, 0.3561577796936035, 4, 0.07454902132312784, 0, 100000, 2.682159423828125, -23996.291015625
2602, -3141.068069651723, 17.472585678100586, 164, 0.0744744723018047, 0, 100000, 4.319645881652832, -31913.84375
2603, -2965.802125690505, 11.001801013946533, 101, 0.0743999978295029, 0, 100000, 4.711811065673828, -31653.326171875
2604, 4085.434403218329, 7.562390327453613, 69, 0.0743255978316734, 0, 100000, 4.350655555725098, -31521.51171875
2605, -2996.5293353600428, 8.907575607299805, 86, 0.07425127223384173, 0, 100000, 4.001489639282227, -31517.560546875
2606, -3212.7746168514714, 18.28728485107422, 175, 0.07417702096160789, 0, 100000, 4.760842800140381, -31718.78515625
