episode, reward, duration, n_steps, epsilon, success_count, memory length, avg_critic_loss, avg_actor_loss
10001, 4549.322372667491, 1.6206324100494385, 304, 0.04996170339735633, 0, 100000, 0.0, 0.0
10002, -9665.233209989965, 12.849725008010864, 2475, 0.04996170339735633, 0, 100000, 0.0, 0.0
10003, -16700.12360984832, 6.483525991439819, 1360, 0.04996170339735633, 0, 100000, 0.0, 0.0
10004, 1015.4216601848602, 4.730269908905029, 986, 0.04996170339735633, 0, 100000, 0.0, 0.0
10005, -18326.438264397904, 19.314800262451172, 3836, 0.04996170339735633, 0, 100000, 0.0, 0.0
10006, -9320.49339831248, 14.143187522888184, 2919, 0.04996170339735633, 0, 100000, 0.0, 0.0
10007, -11597.43588651903, 13.771514654159546, 2677, 0.04996170339735633, 0, 100000, 0.0, 0.0
10008, -29131.615067672916, 20.381787061691284, 4055, 0.04996170339735633, 0, 100000, 0.0, 0.0
